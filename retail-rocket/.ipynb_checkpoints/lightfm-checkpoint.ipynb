{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-11T00:07:50.774381Z",
     "start_time": "2017-09-10T20:07:46.204140-04:00"
    },
    "_cell_guid": "517db2c0-384c-4d80-a22f-a9e70b106ad1",
    "_uuid": "8e818b04925c755d790b5c47236cf563be390bdd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import vstack\n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.218Z"
    },
    "_uuid": "b54ae1cd5376941feb47376b08d1ba53cc5e266f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('../input/events.csv')\n",
    "category_tree = pd.read_csv('../input/category_tree.csv')\n",
    "items1 = pd.read_csv('../input/item_properties_part1.csv')\n",
    "items2 = pd.read_csv('../input/item_properties_part2.csv')\n",
    "items = pd.concat([items1, items2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.223Z"
    },
    "_uuid": "187100d3fe70b6392884c0f9a1c416f0c5f25e94",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_activity_count = dict()\n",
    "for row in events.itertuples():\n",
    "    if row.visitorid not in user_activity_count:\n",
    "        user_activity_count[row.visitorid] = {'view':0 , 'addtocart':0, 'transaction':0};\n",
    "    if row.event == 'addtocart':\n",
    "        user_activity_count[row.visitorid]['addtocart'] += 1 \n",
    "    elif row.event == 'transaction':\n",
    "        user_activity_count[row.visitorid]['transaction'] += 1\n",
    "    elif row.event == 'view':\n",
    "        user_activity_count[row.visitorid]['view'] += 1 \n",
    "\n",
    "d = pd.DataFrame(user_activity_count)\n",
    "dataframe = d.transpose()\n",
    "# Activity range\n",
    "dataframe['activity'] = dataframe['view'] + dataframe['addtocart'] + dataframe['transaction']\n",
    "# removing users with only a single view\n",
    "cleaned_data = dataframe[dataframe['activity']!=1]\n",
    "# all users contains the userids with more than 1 activity in the events (4lac)\n",
    "all_users = set(cleaned_data.index.values)\n",
    "all_items = set(events['itemid'])\n",
    "# todo: we need to clear items which are only viewed once\n",
    "\n",
    "visitorid_to_index_mapping  = {}\n",
    "itemid_to_index_mapping  = {}\n",
    "vid = 0\n",
    "iid = 0\n",
    "for row in events.itertuples():\n",
    "    if row.visitorid in all_users and row.visitorid not in visitorid_to_index_mapping:\n",
    "        visitorid_to_index_mapping[row.visitorid] = vid\n",
    "        vid = vid + 1\n",
    "\n",
    "    if row.itemid in all_items and row.itemid not in itemid_to_index_mapping:\n",
    "        itemid_to_index_mapping[row.itemid] = iid\n",
    "        iid = iid + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.229Z"
    },
    "_uuid": "bee77d682c4c7bab1fb4cdefa2796b5a310a9ae2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_users = len(all_users)\n",
    "n_items = len(all_items)\n",
    "user_to_item_matrix = sp.dok_matrix((n_users, n_items), dtype=np.int8)\n",
    "# We need to check whether we need to add the frequency of view, addtocart and transation.\n",
    "# Currently we are only taking a single value for each row and column.\n",
    "action_weights = [1,2,3]\n",
    "\n",
    "for row in events.itertuples():\n",
    "    if row.visitorid not in all_users:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    mapped_visitor_id = visitorid_to_index_mapping[row.visitorid]\n",
    "    mapped_item_id    = itemid_to_index_mapping[row.itemid]\n",
    "    \n",
    "    value = 0\n",
    "    if row.event == 'view':\n",
    "        value = action_weights[0]\n",
    "    elif row.event == 'addtocart':\n",
    "        value = action_weights[1]        \n",
    "    elif row.event == 'transaction':\n",
    "        value = action_weights[2]\n",
    "        \n",
    "    current_value = user_to_item_matrix[mapped_visitor_id, mapped_item_id]\n",
    "    if value>current_value:\n",
    "        user_to_item_matrix[mapped_visitor_id, mapped_item_id] = value\n",
    "        \n",
    "user_to_item_matrix = user_to_item_matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.236Z"
    },
    "_uuid": "ccbf20008baee3cecf82db05e0664b49aa72a650",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_to_item_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.239Z"
    },
    "_uuid": "8e33c44dd9ef9f09f6b6b50067e5380d9de27ee7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_items = items[items.itemid.isin(all_items)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.243Z"
    },
    "_uuid": "8e73f0d0168f9bb3c5fb41e4e346bf9ef2a08326",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adding a fake property to filtered items, which do not have any property\n",
    "\n",
    "fake_itemid = []\n",
    "fake_timestamp = []\n",
    "fake_property = []\n",
    "fake_value = []\n",
    "all_items_with_property = set(items.itemid)\n",
    "for itx in list(all_items):\n",
    "    if itx not in all_items_with_property:\n",
    "        fake_itemid.insert(0, itx)\n",
    "        fake_timestamp.insert(0, 0)\n",
    "        fake_property.insert(0, 888)\n",
    "        fake_value.insert(0, 0)\n",
    "    \n",
    "fake_property_dict = {'itemid':fake_itemid, 'timestamp':fake_timestamp, 'property':fake_property,\n",
    "                     'value':fake_value}\n",
    "\n",
    "fake_df = pd.DataFrame(fake_property_dict, columns=filtered_items.columns.values)\n",
    "filtered_items = pd.concat([filtered_items, fake_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.247Z"
    },
    "_uuid": "40edd27f6e0ee797824903d62e9aa37cc93bfa7e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_items['itemid'] = filtered_items['itemid'].apply(lambda x: itemid_to_index_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.251Z"
    },
    "_uuid": "d90953db9e2903d0c177849dc750172b1cd8bd76",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_items = filtered_items.sort_values('timestamp', ascending=False).drop_duplicates(['itemid','property'])\n",
    "filtered_items.sort_values(by='itemid', inplace=True)\n",
    "item_to_property_matrix = filtered_items.pivot(index='itemid', columns='property', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.254Z"
    },
    "_uuid": "1083fb3d94a2e5b4f3c3709f52636626ed0b25ab",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_to_property_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.258Z"
    },
    "_uuid": "832fe0a9d44b3d73cd6d2983d49863f8d51963bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_cols = list()\n",
    "cols = item_to_property_matrix.columns\n",
    "for col in cols:\n",
    "    value = len(item_to_property_matrix[col].value_counts())\n",
    "    if value < 50:\n",
    "        useful_cols.insert(0, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.262Z"
    },
    "_uuid": "956319b2d83976ce117e9650cf3e0b89a597bd99",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_to_property_matrix = item_to_property_matrix[useful_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.265Z"
    },
    "_uuid": "1cdbaebca761c65b34567bafab6c194bcd966bb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_to_property_matrix_one_hot_sparse = pd.get_dummies(item_to_property_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.268Z"
    },
    "_uuid": "6532c2f51ade02a3ad776ff4a32d466c6613eb75",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightfm import LightFM\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.271Z"
    },
    "_uuid": "f2d44be8e8bea113fd87a5e4b14e560a209ba68e",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_to_property_matrix_one_hot_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.274Z"
    },
    "_uuid": "31f1c87246835500dbffabf736a78c40c699c4f7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "item_to_property_matrix_sparse = csr_matrix(item_to_property_matrix_one_hot_sparse.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.277Z"
    },
    "_uuid": "a0316d7ab904726461230c1652a6bacd6f81a454",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def make_train(ratings, pct_test = 0.2):\n",
    "    '''\n",
    "    This function will take in the original user-item matrix and \"mask\" a percentage of the original ratings where a\n",
    "    user-item interaction has taken place for use as a test set. The test set will contain all of the original ratings, \n",
    "    while the training set replaces the specified percentage of them with a zero in the original ratings matrix. \n",
    "    \n",
    "    parameters: \n",
    "    \n",
    "    ratings - the original ratings matrix from which you want to generate a train/test set. Test is just a complete\n",
    "    copy of the original set. This is in the form of a sparse csr_matrix. \n",
    "    \n",
    "    pct_test - The percentage of user-item interactions where an interaction took place that you want to mask in the \n",
    "    training set for later comparison to the test set, which contains all of the original ratings. \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    training_set - The altered version of the original data with a certain percentage of the user-item pairs \n",
    "    that originally had interaction set back to zero.\n",
    "    \n",
    "    test_set - A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "    compares with the actual interactions.\n",
    "    \n",
    "    user_inds - From the randomly selected user-item indices, which user rows were altered in the training data.\n",
    "    This will be necessary later when evaluating the performance via AUC.\n",
    "    '''\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.283Z"
    },
    "_uuid": "6b395fa29c5b078d09916cca5358118fb600dcbf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, item_users_altered = make_train(user_to_item_matrix, pct_test = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.287Z"
    },
    "_uuid": "b0a38f51bbb27b2822ce4d780baf33b2896c092c",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_comp, lr, ep = 30, 0.01, 10 \n",
    "model = LightFM(no_components=no_comp, learning_rate=lr, loss='warp')\n",
    "model.fit_partial(\n",
    "        X_train,\n",
    "        item_features=item_to_property_matrix_sparse,\n",
    "        epochs=ep,\n",
    "        num_threads=4,\n",
    "        verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.291Z"
    },
    "_uuid": "5308774b06ad0a169b1c801e530649d23f7894db",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def auc_score(predictions, target):\n",
    "    '''\n",
    "    This simple function will output the area under the curve using sklearn's metrics. \n",
    "    \n",
    "    parameters:\n",
    "    - predictions: your prediction output\n",
    "    - test: the actual target result you are comparing to\n",
    "    returns:\n",
    "    - AUC (area under the Receiver Operating Characterisic curve)\n",
    "    '''\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "def normalise_for_predictions(arr):\n",
    "    arr[arr <= 1.5] = 0\n",
    "    arr[arr > 1.5] = 1\n",
    "    return arr\n",
    "\n",
    "def get_predictions(user_id, model):\n",
    "    pid_array = np.arange(n_items, dtype=np.int32)\n",
    "    uid_array = np.empty(n_items, dtype=np.int32)\n",
    "    uid_array.fill(user_id)\n",
    "    predictions = model.predict(\n",
    "            uid_array,\n",
    "            pid_array,\n",
    "            item_features=item_to_property_matrix_sparse,\n",
    "            num_threads=4)\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "def calc_mean_auc(training_set, altered_users, model, test_set):\n",
    "    '''\n",
    "    This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "    \n",
    "    parameters:\n",
    "    \n",
    "    training_set - The training set resulting from make_train, where a certain percentage of the original\n",
    "    user/item interactions are reset to zero to hide them from the model \n",
    "    \n",
    "    predictions - The matrix of your predicted ratings for each user/item pair as output from the implicit MF.\n",
    "    These should be stored in a list, with user vectors as item zero and item vectors as item one. \n",
    "    \n",
    "    altered_users - The indices of the users where at least one user/item pair was altered from make_train function\n",
    "    \n",
    "    test_set - The test set constucted earlier from make_train function\n",
    "    \n",
    "    \n",
    "    \n",
    "    returns:\n",
    "    \n",
    "    The mean AUC (area under the Receiver Operator Characteristic curve) of the test set only on user-item interactions\n",
    "    there were originally zero to test ranking ability in addition to the most popular items as a benchmark.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "    popularity_auc = [] # To store popular AUC scores\n",
    "    pop_items = np.array(test_set.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "    print (len(altered_users))\n",
    "    index = 0;\n",
    "    for user in altered_users: # Iterate through each user that had an item altered\n",
    "        print (index)\n",
    "        index = index + 1\n",
    "        training_row = training_set[user,:].toarray().reshape(-1) # Get the training set row\n",
    "        zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "        # Get the predicted values based on our user/item vectors\n",
    "        pred = get_predictions(user, model)[zero_inds].reshape(-1)\n",
    "        pred = normalise_for_predictions(pred)\n",
    "        # Get only the items that were originally zero\n",
    "        # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "        actual = test_set[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "        actual = normalise_for_predictions(actual)\n",
    "        # Select the binarized yes/no interaction pairs from the original full data\n",
    "        # that align with the same pairs in training \n",
    "        pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "        store_auc.append(auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "        popularity_auc.append(auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "    # End users iteration\n",
    "    return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "   # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-09-11T00:07:46.307Z"
    },
    "_uuid": "d9830d8ad3807c26815be7402e92346681938509",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_mean_auc(X_train, item_users_altered,  model, X_test)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "coding-env",
   "language": "python",
   "name": "gl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
